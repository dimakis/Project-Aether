# =============================================================================
# Project Aether - Local Development Stack
# =============================================================================
#
# DEPLOYMENT MODES (via profiles):
# --------------------------------
# Development (host Python, containerized infra):
#   podman-compose up -d                    # Infra only (postgres, mlflow, redis)
#   make serve                              # Run API on host with hot-reload
#
# Full Containerized (production-like):
#   podman-compose --profile full up -d     # Everything in containers
#
# With Chat UI:
#   podman-compose --profile ui up -d       # Infra + Open WebUI
#   podman-compose --profile full --profile ui up -d  # All services + UI
#
# Stop:
#   podman-compose down                     # Stop and remove
#   podman-compose down -v                  # Stop and remove with volumes
#
# K8S MIGRATION PATH:
# -------------------
# This compose file is designed to map 1:1 to Kubernetes resources:
# - Each service → Deployment + Service
# - Volumes → PersistentVolumeClaims
# - Networks → Kubernetes Services (ClusterIP/LoadBalancer)
#
# Use `kompose convert` to generate initial K8s manifests from this file.

services:
  # ===========================================================================
  # PostgreSQL Database (Constitution: Principle IV - State)
  # ===========================================================================
  postgres:
    image: docker.io/library/postgres:16-alpine
    container_name: aether-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: aether
      POSTGRES_PASSWORD: aether
      POSTGRES_DB: aether
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U aether -d aether"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================================================
  # MLflow Tracking Server (Constitution: Principle III - Observability)
  # ===========================================================================
  # NOTE: Using SQLite backend because MLflow v3.9.0 has a bug with PostgreSQL
  # that causes trace ingestion to fail with 500 errors. Runs/experiments work
  # fine with PostgreSQL, but traces require SQLite until MLflow fixes the bug.
  # To use PostgreSQL (without traces), set MLFLOW_USE_POSTGRES=true
  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.9.0
    container_name: aether-mlflow
    restart: unless-stopped
    environment:
      MLFLOW_DEFAULT_ARTIFACT_ROOT: /mlflow/artifacts
    ports:
      - "${MLFLOW_PORT:-5002}:5000"
    volumes:
      - mlflow_data:/mlflow/data
      - mlflow_artifacts:/mlflow/artifacts
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/data/mlflow.db
      --default-artifact-root /mlflow/artifacts
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Redis Cache (Optional - for entity caching)
  # ===========================================================================
  redis:
    image: docker.io/library/redis:7-alpine
    container_name: aether-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ===========================================================================
  # Aether Application (profile: full)
  # ===========================================================================
  # Use --profile full to include the application container.
  # Without this profile, run the API on the host for hot-reload development.
  app:
    profiles: ["full"]
    build:
      context: ../..
      dockerfile: infrastructure/podman/Containerfile
    image: aether:latest
    container_name: aether-app
    restart: unless-stopped
    env_file:
      - ../../.env
    environment:
      # Override for container networking
      DATABASE_URL: postgresql+asyncpg://aether:aether@postgres:5432/aether
      MLFLOW_TRACKING_URI: http://mlflow:5000
      REDIS_URL: redis://redis:6379
      # For sandbox: use podman socket
      SANDBOX_PODMAN_SOCKET: /run/podman/podman.sock
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      # Mount podman socket for sandbox container creation
      - /run/user/1000/podman/podman.sock:/run/podman/podman.sock:ro
    depends_on:
      postgres:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ===========================================================================
  # Open WebUI - Chat Interface (profile: ui)
  # ===========================================================================
  # Provides a beautiful chat UI that connects to Aether's OpenAI-compatible API.
  # Access at http://localhost:3000 after starting.
  #
  # Usage:
  #   podman-compose --profile ui up -d                  # UI + infra (API on host)
  #   podman-compose --profile full --profile ui up -d  # UI + containerized API
  #
  # Note: When using --profile ui without --profile full, API must run on host.
  # AETHER_API_URL env var controls where Open WebUI connects:
  #   - Default: http://host.containers.internal:8000/api (host API)
  #   - With --profile full: http://app:8000/api (containerized API)
  open-webui:
    profiles: ["ui"]
    image: ghcr.io/open-webui/open-webui:main
    container_name: aether-webui
    restart: unless-stopped
    environment:
      # Point to Aether's OpenAI-compatible API
      # Override AETHER_API_URL for containerized mode: http://app:8000/api
      OPENAI_API_BASE_URL: ${AETHER_API_URL:-http://host.containers.internal:8000/api}/v1
      OPENAI_API_KEY: ${OPENAI_API_KEY:-sk-aether-local}
      # Disable authentication for local development
      WEBUI_AUTH: "False"
      # Disable telemetry
      SCARF_NO_ANALYTICS: "true"
      DO_NOT_TRACK: "true"
      ANONYMIZED_TELEMETRY: "false"
      # Default model
      DEFAULT_MODELS: "architect"
    ports:
      - "${WEBUI_PORT:-3000}:8080"
    volumes:
      - open_webui_data:/app/backend/data
    extra_hosts:
      # Required for container to reach host on Linux
      - "host.containers.internal:host-gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
    name: aether-postgres-data
  mlflow_data:
    name: aether-mlflow-data
  mlflow_artifacts:
    name: aether-mlflow-artifacts
  redis_data:
    name: aether-redis-data
  open_webui_data:
    name: aether-webui-data

networks:
  default:
    name: aether-network
